#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üóÉÔ∏è Demonstra√ß√£o do Sistema de Cache - UVV InovaWeek Scraper
==========================================================

Este script demonstra como o sistema de cache funciona no scraper UVV InovaWeek.
Voc√™ pode ver a diferen√ßa de performance entre requisi√ß√µes com e sem cache.

Funcionalidades demonstradas:
- Cache autom√°tico de requisi√ß√µes HTTP
- Estat√≠sticas de hit/miss do cache
- Compara√ß√£o de tempo com e sem cache
- Limpeza de cache
- Configura√ß√£o de expira√ß√£o

Autor: ICLearning WebScraping Project
Data: 26/09/2025
"""

import sys
import os
import time
from datetime import datetime

# Adicionar o diret√≥rio pai ao path para importar o scraper
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from scrapers.scraper_uvv_inovaweek_revisado import UVVInovaWeekScraper, CacheManager

def demonstracao_basica():
    """Demonstra o funcionamento b√°sico do cache"""
    print("üóÉÔ∏è === DEMONSTRA√á√ÉO DO SISTEMA DE CACHE ===\n")
    
    # 1. Scraper com cache
    print("1Ô∏è‚É£ Inicializando scraper COM cache...")
    scraper = UVVInovaWeekScraper(use_cache=True)
    
    # URL de teste
    url_teste = "https://www.uvv.br/noticias/"
    
    print("2Ô∏è‚É£ Fazendo primeira requisi√ß√£o (ser√° armazenada no cache)...")
    inicio = time.time()
    response1 = scraper.fazer_requisicao(url_teste)
    tempo1 = time.time() - inicio
    print(f"‚è±Ô∏è Primeira requisi√ß√£o: {tempo1:.2f} segundos")
    
    print("3Ô∏è‚É£ Fazendo segunda requisi√ß√£o (deve vir do cache)...")
    inicio = time.time()
    response2 = scraper.fazer_requisicao(url_teste)
    tempo2 = time.time() - inicio
    print(f"‚è±Ô∏è Segunda requisi√ß√£o: {tempo2:.2f} segundos")
    
    # Calcular melhoria
    if tempo1 > 0 and tempo2 >= 0:
        if tempo2 == 0:
            melhoria = 100
        else:
            melhoria = ((tempo1 - tempo2) / tempo1) * 100
        print(f"üöÄ Melhoria de performance: {melhoria:.1f}% mais r√°pida!")
    
    print("4Ô∏è‚É£ Estat√≠sticas do cache:")
    scraper.print_cache_stats()
    
    try:
        input("\n‚è∏Ô∏è Pressione Enter para continuar...")
    except EOFError:
        print("\n‚è≠Ô∏è Continuando automaticamente...")

def comparacao_com_sem_cache():
    """Compara performance com e sem cache"""
    print("\n‚ö° === COMPARA√á√ÉO: COM CACHE vs SEM CACHE ===\n")
    
    urls_teste = [
        "https://www.uvv.br/noticias/",
        "https://www.uvv.br/noticias/page/2/", 
        "https://www.uvv.br/noticias/page/3/"
    ]
    
    print("1Ô∏è‚É£ Testando SEM cache...")
    scraper_sem_cache = UVVInovaWeekScraper(use_cache=False)
    inicio = time.time()
    for url in urls_teste:
        scraper_sem_cache.fazer_requisicao(url)
    tempo_sem_cache = time.time() - inicio
    print(f"‚è±Ô∏è Tempo SEM cache: {tempo_sem_cache:.2f} segundos")
    
    print("\n2Ô∏è‚É£ Testando COM cache...")
    scraper_com_cache = UVVInovaWeekScraper(use_cache=True)
    
    print("   Primeira passada (populando cache)...")
    inicio = time.time()
    for url in urls_teste:
        scraper_com_cache.fazer_requisicao(url)
    tempo_primeira_passada = time.time() - inicio
    
    print("   Segunda passada (usando cache)...")
    inicio = time.time() 
    for url in urls_teste:
        scraper_com_cache.fazer_requisicao(url)
    tempo_com_cache = time.time() - inicio
    print(f"‚è±Ô∏è Tempo COM cache: {tempo_com_cache:.2f} segundos")
    
    # Calcular melhoria
    if tempo_sem_cache > 0:
        melhoria = ((tempo_sem_cache - tempo_com_cache) / tempo_sem_cache) * 100
        print(f"\nüöÄ Melhoria: {melhoria:.1f}% mais r√°pido!")
        print(f"üíæ Economia de tempo: {tempo_sem_cache - tempo_com_cache:.2f} segundos")
    
    print("\nüìä Estat√≠sticas finais do cache:")
    scraper_com_cache.print_cache_stats()
    
    try:
        input("\n‚è∏Ô∏è Pressione Enter para continuar...")
    except EOFError:
        print("\n‚è≠Ô∏è Continuando automaticamente...")

def gerenciamento_cache():
    """Demonstra gerenciamento do cache"""
    print("\nüîß === GERENCIAMENTO DO CACHE ===\n")
    
    # Criar scraper com cache
    scraper = UVVInovaWeekScraper(use_cache=True)
    
    print("1Ô∏è‚É£ Fazendo algumas requisi√ß√µes para popular o cache...")
    urls = [
        "https://www.uvv.br/noticias/",
        "https://www.uvv.br/noticias/page/2/"
    ]
    
    for i, url in enumerate(urls, 1):
        scraper.fazer_requisicao(url)
        print(f"   ‚úÖ Requisi√ß√£o {i} conclu√≠da")
    
    print("\n2Ô∏è‚É£ Estat√≠sticas atuais do cache:")
    scraper.print_cache_stats()
    
    print("\n3Ô∏è‚É£ Limpando o cache...")
    scraper.clear_cache()
    print("   üßπ Cache limpo!")
    
    print("\n4Ô∏è‚É£ Estat√≠sticas ap√≥s limpeza:")
    scraper.print_cache_stats()
    
    try:
        input("\n‚è∏Ô∏è Pressione Enter para continuar...")
    except EOFError:
        print("\n‚è≠Ô∏è Continuando automaticamente...")

def demonstrar_cache_expiracao():
    """
    ‚è∞ Demonstra funcionamento da expira√ß√£o do cache
    """
    print("\n‚è∞ === EXPIRA√á√ÉO DO CACHE ===\n")
    
    # Criar cache com expira√ß√£o muito curta (1 minuto para demonstra√ß√£o)
    print("1Ô∏è‚É£ Criando scraper com cache de 1 minuto...")
    cache_manager = CacheManager(cache_dir="cache_demo_expiracao", expiration_hours=0.0167)  # ~1 minuto
    
    # Simular cache expirado criando arquivo antigo
    import os
    test_file = os.path.join("cache_demo_expiracao", "test.cache")
    os.makedirs("cache_demo_expiracao", exist_ok=True)
    
    with open(test_file, 'w') as f:
        f.write("cache antigo")
    
    # Alterar timestamp do arquivo para simular expira√ß√£o
    old_time = time.time() - 3600  # 1 hora atr√°s
    os.utime(test_file, (old_time, old_time))
    
    print("2Ô∏è‚É£ Verificando limpeza autom√°tica de cache expirado...")
    cache_manager._clean_expired_cache()
    
    # Verificar se arquivo foi removido
    if not os.path.exists(test_file):
        print("‚úÖ Cache expirado foi removido automaticamente!")
    else:
        print("‚ùå Cache expirado n√£o foi removido")
    
    # Limpar diret√≥rio de teste
    import shutil
    if os.path.exists("cache_demo_expiracao"):
        shutil.rmtree("cache_demo_expiracao")
        print("üßπ Diret√≥rio de teste limpo")

def menu_interativo():
    """
    üìã Menu interativo para demonstra√ß√µes
    """
    while True:
        print("\n" + "="*60)
        print("üóÉÔ∏è DEMONSTRA√á√ÉO DO SISTEMA DE CACHE - UVV SCRAPER")
        print("="*60)
        print("1Ô∏è‚É£  Demonstra√ß√£o b√°sica do cache")
        print("2Ô∏è‚É£  Compara√ß√£o: Com cache vs Sem cache") 
        print("3Ô∏è‚É£  Gerenciamento do cache")
        print("4Ô∏è‚É£  Expira√ß√£o do cache")
        print("5Ô∏è‚É£  Executar scraper real com cache")
        print("0Ô∏è‚É£  Sair")
        print("-"*60)
        
        try:
            escolha = input("Digite sua op√ß√£o: ").strip()
        except EOFError:
            print("\nüëã Entrada finalizada automaticamente.")
            break
        
        try:
            if escolha == "1":
                demonstracao_basica()
            elif escolha == "2":
                comparacao_com_sem_cache()
            elif escolha == "3":
                gerenciamento_cache()
            elif escolha == "4":
                demonstrar_cache_expiracao()
            elif escolha == "5":
                executar_scraper_real()
            elif escolha == "0":
                print("\nüëã Obrigado por usar a demonstra√ß√£o do cache!")
                break
            else:
                print("‚ùå Op√ß√£o inv√°lida! Tente novamente.")
                
        except KeyboardInterrupt:
            print("\n\nüëã Demonstra√ß√£o interrompida pelo usu√°rio.")
            break
        except Exception as e:
            print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
            try:
                input("\n‚è∏Ô∏è Pressione Enter para continuar...")
            except EOFError:
                print("\n‚è≠Ô∏è Continuando automaticamente...")

def executar_scraper_real():
    """
    üöÄ Executa o scraper real com cache habilitado
    """
    print("\nüöÄ === EXECUTANDO SCRAPER REAL COM CACHE ===\n")
    
    scraper = UVVInovaWeekScraper(use_cache=True, cache_hours=24)
    
    print("üéØ Coletando not√≠cias do InovaWeek (primeira p√°gina)...")
    
    try:
        # Executar coleta real
        noticias = scraper.coletar_noticias_inovaweek(
            max_paginas=1  # Apenas primeira p√°gina para demo
        )
        
        print(f"\n‚úÖ Coleta conclu√≠da!")
        print(f"üì∞ Not√≠cias encontradas: {len(noticias)}")
        
        # Mostrar estat√≠sticas do cache
        print("\nüìä Estat√≠sticas do cache:")
        scraper.print_cache_stats()
        
    except Exception as e:
        print(f"‚ùå Erro durante coleta: {e}")

if __name__ == "__main__":
    try:
        menu_interativo()
    except KeyboardInterrupt:
        print("\n\nüëã Demonstra√ß√£o finalizada.")
    except Exception as e:
        print(f"\n‚ùå Erro inesperado: {e}")