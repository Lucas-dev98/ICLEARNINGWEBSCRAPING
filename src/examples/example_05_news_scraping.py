#!/usr/bin/env python3
"""
Exemplo 05 - Scraping de NotÃ­cias e Blogs
=========================================

Este exemplo demonstra como fazer scraping em sites de notÃ­cias para:
- Extrair manchetes e artigos completos
- Coletar metadados (autor, data, categoria)
- Analisar sentimento das notÃ­cias
- Monitorar tendÃªncias de tÃ³picos

IMPORTANTE: Sempre respeite os direitos autorais e robots.txt dos sites!

Autor: ICLearning WebScraping Project
Data: 2025-09-24
"""

# === IMPORTAÃ‡Ã•ES NECESSÃRIAS ===
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from datetime import datetime, timedelta
from urllib.parse import urljoin, urlparse
import json
from collections import Counter
import time

def simular_site_noticias():
    """Simula um site de notÃ­cias para demonstraÃ§Ã£o."""
    html_exemplo = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>Portal de NotÃ­cias Tech</title>
    </head>
    <body>
        <header>
            <h1>TechNews Brasil</h1>
        </header>
        
        <main class="container">
            <!-- NotÃ­cia Principal -->
            <article class="noticia destaque" data-id="1">
                <header class="noticia-header">
                    <h1 class="titulo">InteligÃªncia Artificial revoluciona setor de saÃºde no Brasil</h1>
                    <div class="metadados">
                        <span class="autor">Por JoÃ£o Silva</span>
                        <time class="data-publicacao" datetime="2025-09-24T08:30:00">24/09/2025 08:30</time>
                        <span class="categoria">Tecnologia</span>
                        <span class="tempo-leitura">5 min de leitura</span>
                    </div>
                </header>
                <div class="conteudo">
                    <p class="lead">Hospitais brasileiros comeÃ§am a implementar sistemas de IA para diagnÃ³sticos mais precisos e tratamentos personalizados.</p>
                    <p>A inteligÃªncia artificial estÃ¡ transformando rapidamente o setor de saÃºde brasileiro. Nos Ãºltimos meses, diversos hospitais comeÃ§aram a adotar sistemas de IA para auxiliar em diagnÃ³sticos, especialmente na Ã¡rea de radiologia e oncologia.</p>
                    <p>Segundo dados do MinistÃ©rio da SaÃºde, a implementaÃ§Ã£o dessas tecnologias tem resultado em uma reduÃ§Ã£o de 30% no tempo de diagnÃ³stico e aumento de 25% na precisÃ£o dos resultados.</p>
                </div>
                <div class="tags">
                    <span class="tag">IA</span>
                    <span class="tag">SaÃºde</span>
                    <span class="tag">Brasil</span>
                    <span class="tag">InovaÃ§Ã£o</span>
                </div>
                <div class="engagement">
                    <span class="visualizacoes">12.543 visualizaÃ§Ãµes</span>
                    <span class="compartilhamentos">234 compartilhamentos</span>
                    <span class="comentarios">89 comentÃ¡rios</span>
                </div>
            </article>

            <!-- NotÃ­cia 2 -->
            <article class="noticia" data-id="2">
                <header class="noticia-header">
                    <h2 class="titulo">Startup brasileira desenvolve app para agricultura sustentÃ¡vel</h2>
                    <div class="metadados">
                        <span class="autor">Por Maria Santos</span>
                        <time class="data-publicacao" datetime="2025-09-24T10:15:00">24/09/2025 10:15</time>
                        <span class="categoria">Startups</span>
                        <span class="tempo-leitura">3 min de leitura</span>
                    </div>
                </header>
                <div class="conteudo">
                    <p class="lead">Aplicativo utiliza dados de satÃ©lite e sensores IoT para otimizar uso de recursos na agricultura.</p>
                    <p>A startup AgroTech, com sede em SÃ£o Paulo, lanÃ§ou um aplicativo inovador que combina dados de satÃ©lite com sensores IoT para ajudar agricultores a otimizar o uso de Ã¡gua e fertilizantes.</p>
                    <p>A soluÃ§Ã£o jÃ¡ estÃ¡ sendo testada em 50 propriedades rurais no interior de SÃ£o Paulo, com resultados promissores de reduÃ§Ã£o de 40% no consumo de Ã¡gua.</p>
                </div>
                <div class="tags">
                    <span class="tag">Agricultura</span>
                    <span class="tag">Startup</span>
                    <span class="tag">Sustentabilidade</span>
                    <span class="tag">IoT</span>
                </div>
                <div class="engagement">
                    <span class="visualizacoes">8.921 visualizaÃ§Ãµes</span>
                    <span class="compartilhamentos">156 compartilhamentos</span>
                    <span class="comentarios">43 comentÃ¡rios</span>
                </div>
            </article>

            <!-- NotÃ­cia 3 -->
            <article class="noticia" data-id="3">
                <header class="noticia-header">
                    <h2 class="titulo">Criptomoedas brasileiras ganham espaÃ§o no mercado internacional</h2>
                    <div class="metadados">
                        <span class="autor">Por Carlos Oliveira</span>
                        <time class="data-publicacao" datetime="2025-09-24T14:45:00">24/09/2025 14:45</time>
                        <span class="categoria">FinanÃ§as</span>
                        <span class="tempo-leitura">4 min de leitura</span>
                    </div>
                </header>
                <div class="conteudo">
                    <p class="lead">Tokens desenvolvidos no Brasil comeÃ§am a ser negociados em exchanges internacionais.</p>
                    <p>O cenÃ¡rio de criptomoedas brasileiras estÃ¡ em expansÃ£o, com vÃ¡rias tokens nacionais sendo listadas em exchanges estrangeiras. Especialistas apontam crescimento de 150% no Ãºltimo trimestre.</p>
                    <p>Entre os destaques estÃ£o tokens focados em sustentabilidade e inclusÃ£o financeira, Ã¡reas onde o Brasil tem se mostrado inovador.</p>
                </div>
                <div class="tags">
                    <span class="tag">Criptomoedas</span>
                    <span class="tag">Blockchain</span>
                    <span class="tag">FinanÃ§as</span>
                    <span class="tag">Brasil</span>
                </div>
                <div class="engagement">
                    <span class="visualizacoes">15.672 visualizaÃ§Ãµes</span>
                    <span class="compartilhamentos">298 compartilhamentos</span>
                    <span class="comentarios">127 comentÃ¡rios</span>
                </div>
            </article>

            <!-- NotÃ­cia 4 -->
            <article class="noticia" data-id="4">
                <header class="noticia-header">
                    <h2 class="titulo">EducaÃ§Ã£o digital: Universidades brasileiras lideram pesquisa em IA</h2>
                    <div class="metadados">
                        <span class="autor">Por Ana Costa</span>
                        <time class="data-publicacao" datetime="2025-09-23T16:20:00">23/09/2025 16:20</time>
                        <span class="categoria">EducaÃ§Ã£o</span>
                        <span class="tempo-leitura">6 min de leitura</span>
                    </div>
                </header>
                <div class="conteudo">
                    <p class="lead">Pesquisadores brasileiros publicam estudos inovadores sobre aplicaÃ§Ãµes educacionais da inteligÃªncia artificial.</p>
                    <p>Universidades como USP, UNICAMP e UFMG estÃ£o na vanguarda da pesquisa em IA aplicada Ã  educaÃ§Ã£o, desenvolvendo sistemas adaptativos de aprendizagem.</p>
                    <p>Os projetos incluem tutores virtuais inteligentes e sistemas de recomendaÃ§Ã£o de conteÃºdo personalizado para diferentes perfis de estudantes.</p>
                </div>
                <div class="tags">
                    <span class="tag">EducaÃ§Ã£o</span>
                    <span class="tag">IA</span>
                    <span class="tag">Universidades</span>
                    <span class="tag">Pesquisa</span>
                </div>
                <div class="engagement">
                    <span class="visualizacoes">7.234 visualizaÃ§Ãµes</span>
                    <span class="compartilhamentos">189 compartilhamentos</span>
                    <span class="comentarios">65 comentÃ¡rios</span>
                </div>
            </article>
        </main>
    </body>
    </html>
    """
    return html_exemplo

class NoticiasScraper:
    """
    Scraper especializado em sites de notÃ­cias e blogs.
    
    Funcionalidades:
    - ExtraÃ§Ã£o de manchetes e conteÃºdo completo
    - Coleta de metadados (autor, data, categoria)
    - AnÃ¡lise de engajamento
    - Monitoramento de tendÃªncias
    """
    
    def __init__(self, delay_requests=1):
        """
        Inicializa o scraper de notÃ­cias.
        
        Args:
            delay_requests (int): Delay entre requests em segundos
        """
        self.delay = delay_requests
        self.session = requests.Session()
        
        # Headers apropriados para sites de notÃ­cias
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; NewsBot/1.0; Educational Purpose)',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Cache-Control': 'max-age=0'
        }
        self.session.headers.update(self.headers)
    
    def extrair_data_publicacao(self, elemento_data):
        """
        Extrai e normaliza data de publicaÃ§Ã£o.
        
        Args:
            elemento_data: Elemento BeautifulSoup contendo data
            
        Returns:
            datetime: Data de publicaÃ§Ã£o normalizada
        """
        if not elemento_data:
            return None
        
        # Tentar extrair de atributo datetime primeiro
        datetime_attr = elemento_data.get('datetime')
        if datetime_attr:
            try:
                return datetime.fromisoformat(datetime_attr.replace('Z', '+00:00'))
            except ValueError:
                pass
        
        # Extrair do texto do elemento
        texto_data = elemento_data.get_text().strip()
        
        # PadrÃµes comuns de data em portuguÃªs
        padroes_data = [
            r'(\d{1,2})/(\d{1,2})/(\d{4})\s*(\d{1,2}):(\d{2})',  # 24/09/2025 08:30
            r'(\d{1,2})/(\d{1,2})/(\d{4})',                      # 24/09/2025
            r'(\d{4})-(\d{1,2})-(\d{1,2})\s*(\d{1,2}):(\d{2})',  # 2025-09-24 08:30
            r'(\d{4})-(\d{1,2})-(\d{1,2})',                      # 2025-09-24
        ]
        
        for padrao in padroes_data:
            match = re.search(padrao, texto_data)
            if match:
                try:
                    grupos = match.groups()
                    if len(grupos) >= 3:
                        if '/' in padrao:  # Formato brasileiro
                            dia, mes, ano = grupos[0], grupos[1], grupos[2]
                            hora, minuto = grupos[3:5] if len(grupos) >= 5 else ('0', '0')
                        else:  # Formato ISO
                            ano, mes, dia = grupos[0], grupos[1], grupos[2]
                            hora, minuto = grupos[3:5] if len(grupos) >= 5 else ('0', '0')
                        
                        return datetime(int(ano), int(mes), int(dia), 
                                     int(hora), int(minuto))
                except ValueError:
                    continue
        
        return None
    
    def extrair_numeros_engagement(self, texto):
        """
        Extrai nÃºmeros de engagement (visualizaÃ§Ãµes, comentÃ¡rios, etc.).
        
        Args:
            texto (str): Texto contendo nÃºmeros
            
        Returns:
            int: NÃºmero extraÃ­do
        """
        if not texto:
            return 0
        
        # Extrair nÃºmeros, incluindo formataÃ§Ã£o com pontos/vÃ­rgulas
        numeros = re.findall(r'[\d.,]+', texto)
        if numeros:
            # Remover pontos de milhares
            numero_limpo = numeros[0].replace('.', '').replace(',', '')
            try:
                return int(numero_limpo)
            except ValueError:
                return 0
        return 0
    
    def extrair_tempo_leitura(self, texto):
        """
        Extrai tempo estimado de leitura.
        
        Args:
            texto (str): Texto contendo tempo de leitura
            
        Returns:
            int: Tempo em minutos
        """
        if not texto:
            return 0
        
        # Procurar padrÃµes como "5 min", "3 minutos", etc.
        match = re.search(r'(\d+)\s*(min|minuto)', texto.lower())
        if match:
            return int(match.group(1))
        return 0
    
    def scrape_noticias(self, html_content):
        """
        Extrai notÃ­cias de uma pÃ¡gina de site de notÃ­cias.
        
        Args:
            html_content (str): HTML da pÃ¡gina
            
        Returns:
            list: Lista de notÃ­cias com metadados
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        noticias = []
        
        # Encontrar artigos de notÃ­cias
        elementos_noticia = soup.find_all('article', class_='noticia')
        
        print(f"ğŸ“° Encontradas {len(elementos_noticia)} notÃ­cias na pÃ¡gina")
        
        for i, noticia in enumerate(elementos_noticia, 1):
            noticia_info = {}
            
            # ID da notÃ­cia
            noticia_info['id'] = noticia.get('data-id', f'noticia_{i}')
            
            # TÃ­tulo
            titulo_elem = noticia.find(['h1', 'h2'], class_='titulo')
            noticia_info['titulo'] = titulo_elem.get_text().strip() if titulo_elem else 'N/A'
            
            # Verificar se Ã© destaque
            noticia_info['destaque'] = 'destaque' in noticia.get('class', [])
            
            # Metadados
            metadados = noticia.find('div', class_='metadados')
            if metadados:
                # Autor
                autor_elem = metadados.find('span', class_='autor')
                noticia_info['autor'] = autor_elem.get_text().replace('Por ', '').strip() if autor_elem else 'N/A'
                
                # Data de publicaÃ§Ã£o
                data_elem = metadados.find('time', class_='data-publicacao')
                data_publicacao = self.extrair_data_publicacao(data_elem)
                noticia_info['data_publicacao'] = data_publicacao.isoformat() if data_publicacao else None
                noticia_info['data_publicacao_formatada'] = data_publicacao.strftime('%d/%m/%Y %H:%M') if data_publicacao else 'N/A'
                
                # Calcular idade da notÃ­cia
                if data_publicacao:
                    idade = datetime.now() - data_publicacao
                    noticia_info['horas_publicacao'] = idade.total_seconds() / 3600
                    noticia_info['idade_relativa'] = self.formatar_idade_noticia(idade)
                
                # Categoria
                categoria_elem = metadados.find('span', class_='categoria')
                noticia_info['categoria'] = categoria_elem.get_text().strip() if categoria_elem else 'Geral'
                
                # Tempo de leitura
                tempo_elem = metadados.find('span', class_='tempo-leitura')
                noticia_info['tempo_leitura'] = self.extrair_tempo_leitura(tempo_elem.get_text() if tempo_elem else '')
            
            # Lead (resumo)
            lead_elem = noticia.find('p', class_='lead')
            noticia_info['lead'] = lead_elem.get_text().strip() if lead_elem else ''
            
            # ConteÃºdo completo
            conteudo_div = noticia.find('div', class_='conteudo')
            if conteudo_div:
                paragrafos = conteudo_div.find_all('p')
                conteudo_completo = '\n\n'.join([p.get_text().strip() for p in paragrafos])
                noticia_info['conteudo'] = conteudo_completo
                
                # EstatÃ­sticas do texto
                noticia_info['num_paragrafos'] = len(paragrafos)
                noticia_info['num_caracteres'] = len(conteudo_completo)
                noticia_info['num_palavras'] = len(conteudo_completo.split())
            
            # Tags
            tags_elems = noticia.find_all('span', class_='tag')
            noticia_info['tags'] = [tag.get_text().strip() for tag in tags_elems]
            noticia_info['num_tags'] = len(noticia_info['tags'])
            
            # MÃ©tricas de engajamento
            engagement = noticia.find('div', class_='engagement')
            if engagement:
                # VisualizaÃ§Ãµes
                views_elem = engagement.find('span', class_='visualizacoes')
                noticia_info['visualizacoes'] = self.extrair_numeros_engagement(
                    views_elem.get_text() if views_elem else ''
                )
                
                # Compartilhamentos
                shares_elem = engagement.find('span', class_='compartilhamentos')
                noticia_info['compartilhamentos'] = self.extrair_numeros_engagement(
                    shares_elem.get_text() if shares_elem else ''
                )
                
                # ComentÃ¡rios
                comments_elem = engagement.find('span', class_='comentarios')
                noticia_info['comentarios'] = self.extrair_numeros_engagement(
                    comments_elem.get_text() if comments_elem else ''
                )
                
                # Calcular engagement total
                noticia_info['engagement_total'] = (
                    noticia_info['compartilhamentos'] + 
                    noticia_info['comentarios']
                )
                
                # Taxa de engajamento (se houver visualizaÃ§Ãµes)
                if noticia_info['visualizacoes'] > 0:
                    noticia_info['taxa_engajamento'] = (
                        noticia_info['engagement_total'] / noticia_info['visualizacoes'] * 100
                    )
            
            # Timestamp da coleta
            noticia_info['coletado_em'] = datetime.now().isoformat()
            
            noticias.append(noticia_info)
        
        return noticias
    
    def formatar_idade_noticia(self, idade):
        """
        Formata idade da notÃ­cia em texto legÃ­vel.
        
        Args:
            idade (timedelta): DiferenÃ§a de tempo
            
        Returns:
            str: Idade formatada
        """
        if idade.days > 0:
            return f"{idade.days} dia(s) atrÃ¡s"
        elif idade.seconds > 3600:
            horas = idade.seconds // 3600
            return f"{horas} hora(s) atrÃ¡s"
        elif idade.seconds > 60:
            minutos = idade.seconds // 60
            return f"{minutos} minuto(s) atrÃ¡s"
        else:
            return "Agora mesmo"
    
    def analisar_tendencias(self, noticias):
        """
        Analisa tendÃªncias nas notÃ­cias coletadas.
        
        Args:
            noticias (list): Lista de notÃ­cias
            
        Returns:
            dict: AnÃ¡lise de tendÃªncias
        """
        if not noticias:
            return {'erro': 'Nenhuma notÃ­cia para analisar'}
        
        df = pd.DataFrame(noticias)
        
        # Contadores
        todas_tags = []
        todas_categorias = []
        todos_autores = []
        
        for noticia in noticias:
            todas_tags.extend(noticia.get('tags', []))
            todas_categorias.append(noticia.get('categoria', 'Geral'))
            todos_autores.append(noticia.get('autor', 'N/A'))
        
        analise = {
            'total_noticias': len(noticias),
            'noticias_destaque': len([n for n in noticias if n.get('destaque')]),
            
            # TendÃªncias de tÃ³picos
            'tags_populares': dict(Counter(todas_tags).most_common(10)),
            'categorias_populares': dict(Counter(todas_categorias).most_common(5)),
            'autores_ativos': dict(Counter(todos_autores).most_common(5)),
            
            # MÃ©tricas de engajamento
            'total_visualizacoes': sum(n.get('visualizacoes', 0) for n in noticias),
            'total_compartilhamentos': sum(n.get('compartilhamentos', 0) for n in noticias),
            'total_comentarios': sum(n.get('comentarios', 0) for n in noticias),
            
            # MÃ©tricas de conteÃºdo
            'tempo_leitura_medio': sum(n.get('tempo_leitura', 0) for n in noticias) / len(noticias),
            'palavras_media': sum(n.get('num_palavras', 0) for n in noticias) / len(noticias),
        }
        
        # NotÃ­cia mais popular
        if df['visualizacoes'].sum() > 0:
            mais_popular = df.loc[df['visualizacoes'].idxmax()]
            analise['noticia_mais_popular'] = {
                'titulo': mais_popular['titulo'],
                'visualizacoes': mais_popular['visualizacoes'],
                'autor': mais_popular['autor']
            }
        
        # Melhor engajamento
        if 'taxa_engajamento' in df.columns and not df['taxa_engajamento'].isna().all():
            melhor_engajamento = df.loc[df['taxa_engajamento'].idxmax()]
            analise['melhor_engajamento'] = {
                'titulo': melhor_engajamento['titulo'],
                'taxa': melhor_engajamento['taxa_engajamento'],
                'categoria': melhor_engajamento['categoria']
            }
        
        return analise

def exemplo_uso():
    """Demonstra o uso prÃ¡tico do NoticiasScraper."""
    print("ğŸ“° === EXEMPLO DE SCRAPING DE NOTÃCIAS ===")
    print("=" * 50)
    
    # Inicializar scraper
    scraper = NoticiasScraper(delay_requests=1)
    
    # Simular site de notÃ­cias (em produÃ§Ã£o seria requests.get())
    print("1ï¸âƒ£ Obtendo dados do site de notÃ­cias...")
    html_content = simular_site_noticias()
    
    # Extrair notÃ­cias
    print("2ï¸âƒ£ Extraindo notÃ­cias da pÃ¡gina...")
    noticias = scraper.scrape_noticias(html_content)
    
    # Exibir notÃ­cias encontradas
    print(f"\nğŸ“‹ === NOTÃCIAS EXTRAÃDAS ({len(noticias)}) ===")
    for i, noticia in enumerate(noticias, 1):
        print(f"\nğŸ“° NotÃ­cia {i} {'ğŸŒŸ DESTAQUE' if noticia.get('destaque') else ''}")
        print(f"   ğŸ“„ {noticia['titulo']}")
        print(f"   âœï¸  {noticia['autor']} | ğŸ“… {noticia['data_publicacao_formatada']}")
        print(f"   ğŸ·ï¸  {noticia['categoria']} | â±ï¸  {noticia['tempo_leitura']} min leitura")
        
        if noticia.get('lead'):
            print(f"   ğŸ“ {noticia['lead']}")
        
        if noticia.get('tags'):
            print(f"   ğŸª Tags: {', '.join(noticia['tags'])}")
        
        print(f"   ğŸ‘€ {noticia.get('visualizacoes', 0):,} visualizaÃ§Ãµes")
        print(f"   ğŸ”„ {noticia.get('compartilhamentos', 0)} compartilhamentos")
        print(f"   ğŸ’¬ {noticia.get('comentarios', 0)} comentÃ¡rios")
        
        if noticia.get('taxa_engajamento'):
            print(f"   ğŸ“Š Taxa engajamento: {noticia['taxa_engajamento']:.2f}%")
        
        if noticia.get('idade_relativa'):
            print(f"   ğŸ• {noticia['idade_relativa']}")
    
    # AnÃ¡lise de tendÃªncias
    print(f"\nğŸ“Š === ANÃLISE DE TENDÃŠNCIAS ===")
    analise = scraper.analisar_tendencias(noticias)
    
    print(f"ğŸ“ˆ Total de notÃ­cias: {analise['total_noticias']}")
    print(f"ğŸŒŸ NotÃ­cias em destaque: {analise['noticias_destaque']}")
    print(f"ğŸ‘€ Total de visualizaÃ§Ãµes: {analise['total_visualizacoes']:,}")
    print(f"ğŸ”„ Total de compartilhamentos: {analise['total_compartilhamentos']:,}")
    print(f"ğŸ’¬ Total de comentÃ¡rios: {analise['total_comentarios']:,}")
    print(f"â±ï¸  Tempo mÃ©dio de leitura: {analise['tempo_leitura_medio']:.1f} min")
    print(f"ğŸ“ Palavras por notÃ­cia: {analise['palavras_media']:.0f}")
    
    # Tags populares
    if analise['tags_populares']:
        print(f"\nğŸ”¥ Tags mais populares:")
        for tag, count in list(analise['tags_populares'].items())[:5]:
            print(f"   â€¢ {tag}: {count} notÃ­cias")
    
    # Categorias populares
    if analise['categorias_populares']:
        print(f"\nğŸ“‚ Categorias mais ativas:")
        for categoria, count in analise['categorias_populares'].items():
            print(f"   â€¢ {categoria}: {count} notÃ­cias")
    
    # Autores ativos
    if analise['autores_ativos']:
        print(f"\nâœï¸  Autores mais ativos:")
        for autor, count in list(analise['autores_ativos'].items())[:3]:
            print(f"   â€¢ {autor}: {count} notÃ­cias")
    
    # NotÃ­cia mais popular
    if 'noticia_mais_popular' in analise:
        popular = analise['noticia_mais_popular']
        print(f"\nğŸ† NotÃ­cia mais popular:")
        print(f"   ğŸ“„ {popular['titulo']}")
        print(f"   ğŸ‘€ {popular['visualizacoes']:,} visualizaÃ§Ãµes")
        print(f"   âœï¸  {popular['autor']}")
    
    # Melhor engajamento
    if 'melhor_engajamento' in analise:
        engajamento = analise['melhor_engajamento']
        print(f"\nğŸ“Š Melhor engajamento:")
        print(f"   ğŸ“„ {engajamento['titulo']}")
        print(f"   ğŸ“ˆ {engajamento['taxa']:.2f}% de engajamento")
        print(f"   ğŸ·ï¸  {engajamento['categoria']}")
    
    # Salvar dados
    print(f"\nğŸ’¾ Salvando dados...")
    df = pd.DataFrame(noticias)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # CSV das notÃ­cias
    filename_csv = f"noticias_{timestamp}.csv"
    df.to_csv(filename_csv, index=False, encoding='utf-8')
    print(f"âœ… NotÃ­cias salvas em: {filename_csv}")
    
    # JSON da anÃ¡lise
    filename_json = f"analise_tendencias_{timestamp}.json"
    with open(filename_json, 'w', encoding='utf-8') as f:
        json.dump(analise, f, ensure_ascii=False, indent=2, default=str)
    print(f"âœ… AnÃ¡lise salva em: {filename_json}")
    
    # Dicas para uso real
    print(f"\nğŸ’¡ === APLICAÃ‡Ã•ES PRÃTICAS ===")
    aplicacoes = [
        "ğŸ“Š Monitoramento de trending topics",
        "ğŸ¯ AnÃ¡lise de sentimento de notÃ­cias",
        "ğŸ“ˆ Tracking de menÃ§Ãµes de marca/pessoa",
        "ğŸ” Descoberta de fontes de notÃ­cias",
        "ğŸ“¢ Alertas para palavras-chave especÃ­ficas",
        "ğŸ“° AgregaÃ§Ã£o automÃ¡tica de notÃ­cias",
        "ğŸ·ï¸  ClassificaÃ§Ã£o automÃ¡tica por tÃ³pico",
        "âš¡ Feed personalizado de notÃ­cias"
    ]
    
    for app in aplicacoes:
        print(f"   {app}")
    
    print(f"\nğŸ”§ === DICAS PARA PRODUÃ‡ÃƒO ===")
    dicas = [
        "â±ï¸  Use delays apropriados entre requests",
        "ğŸ”„ Implemente cache para evitar re-scraping",
        "ğŸ“Š Configure banco de dados para histÃ³rico",
        "ğŸ¤– Respeite robots.txt e rate limits",
        "ğŸ“§ Configure alertas para breaking news",
        "ğŸ” Use proxies se necessÃ¡rio",
        "ğŸ“ˆ Monitore mÃ©tricas de qualidade dos dados",
        "ğŸ›¡ï¸  Trate exceÃ§Ãµes de rede adequadamente"
    ]
    
    for dica in dicas:
        print(f"   {dica}")

if __name__ == "__main__":
    exemplo_uso()