#!/usr/bin/env python3
"""
Exemplo 07 - Scraping de Redes Sociais e APIs P√∫blicas
=======================================================

Este exemplo demonstra como fazer scraping em redes sociais e APIs p√∫blicas com:
- Rate limiting e controle de requisi√ß√µes
- An√°lise de engagement e m√©tricas sociais
- Processamento de dados em tempo real
- Monitoramento de tend√™ncias

IMPORTANTE: Sempre respeite os termos de uso e pol√≠ticas de API das plataformas!

Autor: ICLearning WebScraping Project  
Data: 2025-09-24
"""

# === IMPORTA√á√ïES NECESS√ÅRIAS ===
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
import re
from datetime import datetime, timedelta
from urllib.parse import urljoin, urlparse, parse_qs
from collections import Counter, defaultdict
import time
import hashlib
from dataclasses import dataclass
from typing import List, Dict, Optional
import threading
import queue

def simular_rede_social():
    """Simula uma rede social p√∫blica para demonstra√ß√£o."""
    html_exemplo = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>SocialHub - Rede Social de Desenvolvedores</title>
        <meta name="description" content="Comunidade de desenvolvedores">
    </head>
    <body>
        <div class="container">
            <!-- Post 1 -->
            <article class="post" data-post-id="post001" data-timestamp="2025-09-24T10:30:00Z">
                <header class="post-header">
                    <div class="user-info">
                        <img src="/avatars/maria_dev.jpg" alt="Maria Dev" class="avatar">
                        <div class="user-details">
                            <h3 class="username">@maria_dev</h3>
                            <span class="user-title">Full Stack Developer</span>
                            <span class="followers" data-count="15420">15.4K seguidores</span>
                        </div>
                    </div>
                    <time class="post-time" datetime="2025-09-24T10:30:00Z">h√° 2 horas</time>
                </header>
                
                <div class="post-content">
                    <p class="post-text">
                        üöÄ Acabei de lan√ßar uma nova biblioteca Python para web scraping! 
                        Ela inclui rate limiting autom√°tico, cache inteligente e suporte a JavaScript. 
                        
                        O que acham? Feedback √© sempre bem-vindo! 
                        
                        #Python #WebScraping #OpenSource #Development
                    </p>
                    
                    <div class="post-media">
                        <img src="/posts/webscraper_lib.png" alt="Screenshot da biblioteca" class="post-image">
                    </div>
                    
                    <div class="post-links">
                        <a href="https://github.com/maria_dev/awesome-scraper" class="external-link">
                            üîó github.com/maria_dev/awesome-scraper
                        </a>
                    </div>
                </div>
                
                <footer class="post-interactions">
                    <div class="engagement-stats">
                        <button class="like-btn" data-count="234">
                            ‚ù§Ô∏è 234 curtidas
                        </button>
                        <button class="comment-btn" data-count="45">
                            üí¨ 45 coment√°rios
                        </button>
                        <button class="share-btn" data-count="67">
                            üîÑ 67 compartilhamentos
                        </button>
                        <button class="save-btn" data-count="89">
                            üîñ 89 salvamentos
                        </button>
                    </div>
                    
                    <div class="hashtags">
                        <span class="hashtag">#Python</span>
                        <span class="hashtag">#WebScraping</span>
                        <span class="hashtag">#OpenSource</span>
                        <span class="hashtag">#Development</span>
                    </div>
                </footer>
            </article>

            <!-- Post 2 -->
            <article class="post" data-post-id="post002" data-timestamp="2025-09-24T09:15:00Z">
                <header class="post-header">
                    <div class="user-info">
                        <img src="/avatars/carlos_ai.jpg" alt="Carlos AI" class="avatar">
                        <div class="user-details">
                            <h3 class="username">@carlos_ai</h3>
                            <span class="user-title">AI/ML Engineer</span>
                            <span class="followers" data-count="28750">28.7K seguidores</span>
                        </div>
                    </div>
                    <time class="post-time" datetime="2025-09-24T09:15:00Z">h√° 3 horas</time>
                </header>
                
                <div class="post-content">
                    <p class="post-text">
                        ü§ñ Thread sobre as tend√™ncias de IA em 2025:
                        
                        1/5 - LLMs est√£o se tornando mais eficientes
                        2/5 - Edge AI est√° crescendo exponencialmente 
                        3/5 - Computer Vision atinge novos patamares
                        4/5 - NLP conversacional evolui rapidamente
                        5/5 - √âtica em IA ganha mais import√¢ncia
                        
                        Qual tend√™ncia voc√™s acham mais promissora? 
                        
                        #AI #MachineLearning #Tech2025 #Innovation
                    </p>
                </div>
                
                <footer class="post-interactions">
                    <div class="engagement-stats">
                        <button class="like-btn" data-count="892">
                            ‚ù§Ô∏è 892 curtidas
                        </button>
                        <button class="comment-btn" data-count="156">
                            üí¨ 156 coment√°rios
                        </button>
                        <button class="share-btn" data-count="203">
                            üîÑ 203 compartilhamentos
                        </button>
                        <button class="save-btn" data-count="445">
                            üîñ 445 salvamentos
                        </button>
                    </div>
                    
                    <div class="hashtags">
                        <span class="hashtag">#AI</span>
                        <span class="hashtag">#MachineLearning</span>
                        <span class="hashtag">#Tech2025</span>
                        <span class="hashtag">#Innovation</span>
                    </div>
                </footer>
            </article>

            <!-- Post 3 -->
            <article class="post viral" data-post-id="post003" data-timestamp="2025-09-23T16:45:00Z">
                <header class="post-header">
                    <div class="user-info">
                        <img src="/avatars/ana_data.jpg" alt="Ana Data" class="avatar">
                        <div class="user-details">
                            <h3 class="username">@ana_data</h3>
                            <span class="user-title">Data Scientist</span>
                            <span class="followers" data-count="42300">42.3K seguidores</span>
                        </div>
                    </div>
                    <time class="post-time" datetime="2025-09-23T16:45:00Z">ontem</time>
                    <span class="viral-badge">üî• VIRAL</span>
                </header>
                
                <div class="post-content">
                    <p class="post-text">
                        üìä An√°lise: Sal√°rios em Tech 2025
                        
                        Baseado em 10K+ dados coletados:
                        
                        ‚Ä¢ Junior Dev: R$ 4.5K - R$ 8K
                        ‚Ä¢ Pleno Dev: R$ 8K - R$ 15K  
                        ‚Ä¢ Senior Dev: R$ 15K - R$ 25K
                        ‚Ä¢ Tech Lead: R$ 20K - R$ 35K
                        ‚Ä¢ Data Scientist: R$ 12K - R$ 30K
                        
                        Stack que mais paga: Python + Cloud + IA
                        
                        Thread completa com gr√°ficos nos coment√°rios ‚¨áÔ∏è
                        
                        #Tech #Salarios #CarreiraeDev #DataScience
                    </p>
                    
                    <div class="post-media">
                        <img src="/posts/salary_chart.png" alt="Gr√°fico de sal√°rios" class="post-image">
                    </div>
                </div>
                
                <footer class="post-interactions">
                    <div class="engagement-stats">
                        <button class="like-btn" data-count="2847">
                            ‚ù§Ô∏è 2.8K curtidas
                        </button>
                        <button class="comment-btn" data-count="456">
                            üí¨ 456 coment√°rios
                        </button>
                        <button class="share-btn" data-count="1203">
                            üîÑ 1.2K compartilhamentos
                        </button>
                        <button class="save-btn" data-count="1689">
                            üîñ 1.7K salvamentos
                        </button>
                    </div>
                    
                    <div class="hashtags">
                        <span class="hashtag">#Tech</span>
                        <span class="hashtag">#Salarios</span>
                        <span class="hashtag">#CarreiraeDev</span>
                        <span class="hashtag">#DataScience</span>
                    </div>
                </footer>
            </article>

            <!-- Post 4 -->
            <article class="post" data-post-id="post004" data-timestamp="2025-09-23T14:20:00Z">
                <header class="post-header">
                    <div class="user-info">
                        <img src="/avatars/joao_mobile.jpg" alt="Jo√£o Mobile" class="avatar">
                        <div class="user-details">
                            <h3 class="username">@joao_mobile</h3>
                            <span class="user-title">Mobile Developer</span>
                            <span class="followers" data-count="19800">19.8K seguidores</span>
                        </div>
                    </div>
                    <time class="post-time" datetime="2025-09-23T14:20:00Z">ontem</time>
                </header>
                
                <div class="post-content">
                    <p class="post-text">
                        üì± Dica r√°pida para devs React Native:
                        
                        Sempre testem a performance em dispositivos reais, n√£o apenas no simulador!
                        
                        Descobri um vazamento de mem√≥ria que s√≥ aparecia em Android real üòÖ
                        
                        Tools que salvam:
                        ‚úÖ Flipper
                        ‚úÖ Reactotron  
                        ‚úÖ Android Studio Profiler
                        ‚úÖ Xcode Instruments
                        
                        #ReactNative #Mobile #Performance #Development
                    </p>
                </div>
                
                <footer class="post-interactions">
                    <div class="engagement-stats">
                        <button class="like-btn" data-count="387">
                            ‚ù§Ô∏è 387 curtidas
                        </button>
                        <button class="comment-btn" data-count="73">
                            üí¨ 73 coment√°rios
                        </button>
                        <button class="share-btn" data-count="95">
                            üîÑ 95 compartilhamentos
                        </button>
                        <button class="save-btn" data-count="234">
                            üîñ 234 salvamentos
                        </button>
                    </div>
                    
                    <div class="hashtags">
                        <span class="hashtag">#ReactNative</span>
                        <span class="hashtag">#Mobile</span>
                        <span class="hashtag">#Performance</span>
                        <span class="hashtag">#Development</span>
                    </div>
                </footer>
            </article>

            <!-- Post 5 -->
            <article class="post promoted" data-post-id="post005" data-timestamp="2025-09-23T11:30:00Z">
                <header class="post-header">
                    <div class="user-info">
                        <img src="/avatars/techcorp.jpg" alt="TechCorp" class="avatar">
                        <div class="user-details">
                            <h3 class="username">@techcorp</h3>
                            <span class="user-title">Empresa ‚Ä¢ Tecnologia</span>
                            <span class="followers" data-count="156700">156.7K seguidores</span>
                        </div>
                    </div>
                    <time class="post-time" datetime="2025-09-23T11:30:00Z">ontem</time>
                    <span class="promoted-badge">üì¢ PROMOVIDO</span>
                </header>
                
                <div class="post-content">
                    <p class="post-text">
                        üöÄ Estamos contratando Desenvolvedores Python!
                        
                        Posi√ß√µes dispon√≠veis:
                        ‚Ä¢ Python Backend Developer (Pleno)
                        ‚Ä¢ Data Engineer (Senior)
                        ‚Ä¢ DevOps Engineer (Pleno/Senior)
                        
                        Benef√≠cios:
                        ‚úÖ Remoto 100%
                        ‚úÖ Hor√°rio flex√≠vel
                        ‚úÖ PLR + Stock Options
                        ‚úÖ Budget para cursos
                        ‚úÖ Setup home office
                        
                        Interessados? Link na bio ou DM! 
                        
                        #Jobs #Python #Remote #Hiring #TechJobs
                    </p>
                </div>
                
                <footer class="post-interactions">
                    <div class="engagement-stats">
                        <button class="like-btn" data-count="1245">
                            ‚ù§Ô∏è 1.2K curtidas
                        </button>
                        <button class="comment-btn" data-count="289">
                            üí¨ 289 coment√°rios
                        </button>
                        <button class="share-btn" data-count="567">
                            üîÑ 567 compartilhamentos
                        </button>
                        <button class="save-btn" data-count="892">
                            üîñ 892 salvamentos
                        </button>
                    </div>
                    
                    <div class="hashtags">
                        <span class="hashtag">#Jobs</span>
                        <span class="hashtag">#Python</span>
                        <span class="hashtag">#Remote</span>
                        <span class="hashtag">#Hiring</span>
                        <span class="hashtag">#TechJobs</span>
                    </div>
                </footer>
            </article>
        </div>

        <!-- API Endpoints simulados -->
        <script type="application/json" id="trending-topics">
        {
            "trending": [
                {"tag": "Python", "posts": 1247, "engagement": 45230, "growth": 12.5},
                {"tag": "AI", "posts": 892, "engagement": 67890, "growth": 23.8},
                {"tag": "WebScraping", "posts": 234, "engagement": 12340, "growth": 45.2},
                {"tag": "ReactNative", "posts": 567, "engagement": 23450, "growth": 8.7},
                {"tag": "DataScience", "posts": 445, "engagement": 34560, "growth": 15.3}
            ]
        }
        </script>

        <script type="application/json" id="user-analytics">
        {
            "analytics": {
                "total_users": 125000,
                "active_24h": 34500,
                "posts_24h": 2840,
                "engagement_rate": 7.8,
                "top_content_types": [
                    {"type": "tutorial", "percentage": 35},
                    {"type": "discussion", "percentage": 28},
                    {"type": "news", "percentage": 20},
                    {"type": "job_posting", "percentage": 12},
                    {"type": "meme", "percentage": 5}
                ]
            }
        }
        </script>
    </body>
    </html>
    """
    return html_exemplo

@dataclass
class RateLimiter:
    """Controlador de rate limiting para APIs."""
    requests_per_second: float
    requests_per_minute: int
    requests_per_hour: int
    
    def __post_init__(self):
        self.request_times = []
        self.lock = threading.Lock()
    
    def can_make_request(self) -> bool:
        """Verifica se pode fazer uma nova requisi√ß√£o."""
        now = time.time()
        
        with self.lock:
            # Remove requisi√ß√µes antigas (mais de 1 hora)
            self.request_times = [t for t in self.request_times if now - t < 3600]
            
            # Verifica limites
            recent_1s = len([t for t in self.request_times if now - t < 1])
            recent_1m = len([t for t in self.request_times if now - t < 60])
            recent_1h = len(self.request_times)
            
            return (recent_1s < self.requests_per_second and
                    recent_1m < self.requests_per_minute and
                    recent_1h < self.requests_per_hour)
    
    def record_request(self):
        """Registra uma nova requisi√ß√£o."""
        with self.lock:
            self.request_times.append(time.time())
    
    def wait_time(self) -> float:
        """Retorna tempo necess√°rio para esperar antes da pr√≥xima requisi√ß√£o."""
        if self.can_make_request():
            return 0
        return 1 / self.requests_per_second

class SocialMediaScraper:
    """
    Scraper especializado em redes sociais com rate limiting e an√°lise de engagement.
    
    Funcionalidades:
    - Rate limiting autom√°tico
    - Extra√ß√£o de posts e intera√ß√µes
    - An√°lise de engagement
    - Monitoramento de tend√™ncias
    - Processamento de hashtags
    """
    
    def __init__(self, requests_per_second=1, requests_per_minute=30, requests_per_hour=500):
        """
        Inicializa o scraper de redes sociais.
        
        Args:
            requests_per_second (float): Limite de requests por segundo
            requests_per_minute (int): Limite de requests por minuto  
            requests_per_hour (int): Limite de requests por hora
        """
        self.rate_limiter = RateLimiter(requests_per_second, requests_per_minute, requests_per_hour)
        self.session = requests.Session()
        
        # Headers apropriados para redes sociais
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (compatible; SocialBot/1.0; Research Purpose)',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache'
        }
        self.session.headers.update(self.headers)
        
        # Cache para evitar requests desnecess√°rios
        self.cache = {}
        self.cache_duration = 300  # 5 minutos
    
    def make_request_with_limit(self, url: str, **kwargs) -> requests.Response:
        """
        Faz requisi√ß√£o respeitando rate limiting.
        
        Args:
            url (str): URL para requisi√ß√£o
            **kwargs: Argumentos adicionais para requests
            
        Returns:
            requests.Response: Resposta da requisi√ß√£o
        """
        # Verifica cache primeiro
        cache_key = hashlib.md5(f"{url}{str(kwargs)}".encode()).hexdigest()
        if cache_key in self.cache:
            cached_time, cached_response = self.cache[cache_key]
            if time.time() - cached_time < self.cache_duration:
                print(f"üóÑÔ∏è  Usando cache para: {url}")
                return cached_response
        
        # Rate limiting
        while not self.rate_limiter.can_make_request():
            wait_time = self.rate_limiter.wait_time()
            print(f"‚è±Ô∏è  Rate limit atingido. Aguardando {wait_time:.2f}s...")
            time.sleep(wait_time)
        
        # Fazer requisi√ß√£o
        self.rate_limiter.record_request()
        response = self.session.get(url, **kwargs)
        
        # Armazenar no cache
        self.cache[cache_key] = (time.time(), response)
        
        return response
    
    def extrair_engagement(self, interaction_elem):
        """
        Extrai m√©tricas de engagement de um elemento.
        
        Args:
            interaction_elem: Elemento BeautifulSoup com intera√ß√µes
            
        Returns:
            dict: M√©tricas de engagement
        """
        engagement = {
            'likes': 0,
            'comments': 0,
            'shares': 0,
            'saves': 0,
            'total_engagement': 0,
            'engagement_rate': 0.0
        }
        
        if not interaction_elem:
            return engagement
        
        # Extrair likes
        like_btn = interaction_elem.find('button', class_='like-btn')
        if like_btn:
            count = like_btn.get('data-count', '0')
            engagement['likes'] = self.parse_count(count)
        
        # Extrair coment√°rios
        comment_btn = interaction_elem.find('button', class_='comment-btn')
        if comment_btn:
            count = comment_btn.get('data-count', '0')
            engagement['comments'] = self.parse_count(count)
        
        # Extrair compartilhamentos
        share_btn = interaction_elem.find('button', class_='share-btn')
        if share_btn:
            count = share_btn.get('data-count', '0')
            engagement['shares'] = self.parse_count(count)
        
        # Extrair salvamentos
        save_btn = interaction_elem.find('button', class_='save-btn')
        if save_btn:
            count = save_btn.get('data-count', '0')
            engagement['saves'] = self.parse_count(count)
        
        # Calcular total
        engagement['total_engagement'] = (
            engagement['likes'] +
            engagement['comments'] +
            engagement['shares'] +
            engagement['saves']
        )
        
        return engagement
    
    def parse_count(self, count_str: str) -> int:
        """
        Converte string de contador (ex: "2.8K", "1.2M") para n√∫mero.
        
        Args:
            count_str (str): String do contador
            
        Returns:
            int: N√∫mero convertido
        """
        if not count_str:
            return 0
        
        count_str = str(count_str).upper().replace(',', '.')
        
        if 'K' in count_str:
            number = float(count_str.replace('K', ''))
            return int(number * 1000)
        elif 'M' in count_str:
            number = float(count_str.replace('M', ''))
            return int(number * 1000000)
        elif 'B' in count_str:
            number = float(count_str.replace('B', ''))
            return int(number * 1000000000)
        else:
            try:
                return int(float(count_str))
            except ValueError:
                return 0
    
    def extrair_hashtags(self, texto: str, elementos_hashtag=None) -> List[str]:
        """
        Extrai hashtags do texto ou elementos espec√≠ficos.
        
        Args:
            texto (str): Texto para extrair hashtags
            elementos_hashtag: Elementos HTML com hashtags
            
        Returns:
            list: Lista de hashtags
        """
        hashtags = []
        
        # Extrair de elementos espec√≠ficos primeiro
        if elementos_hashtag:
            hashtag_spans = elementos_hashtag.find_all('span', class_='hashtag')
            for span in hashtag_spans:
                tag = span.get_text().strip()
                if tag.startswith('#'):
                    hashtags.append(tag)
        
        # Extrair do texto tamb√©m
        if texto:
            hashtags_texto = re.findall(r'#\w+', texto)
            hashtags.extend(hashtags_texto)
        
        # Remover duplicatas e retornar
        return list(set(hashtags))
    
    def calcular_engagement_rate(self, engagement: dict, followers: int) -> float:
        """
        Calcula taxa de engagement baseada no n√∫mero de seguidores.
        
        Args:
            engagement (dict): M√©tricas de engagement
            followers (int): N√∫mero de seguidores
            
        Returns:
            float: Taxa de engagement em percentual
        """
        if followers == 0:
            return 0.0
        
        total_engagement = engagement.get('total_engagement', 0)
        return (total_engagement / followers) * 100
    
    def scrape_posts(self, html_content: str) -> List[Dict]:
        """
        Extrai posts de uma rede social.
        
        Args:
            html_content (str): HTML da p√°gina
            
        Returns:
            list: Lista de posts com m√©tricas completas
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        posts = []
        
        # Encontrar elementos de posts
        elementos_post = soup.find_all('article', class_='post')
        
        print(f"üì± Encontrados {len(elementos_post)} posts na rede social")
        
        for i, post in enumerate(elementos_post, 1):
            post_info = {}
            
            # ID e metadados b√°sicos
            post_info['id'] = post.get('data-post-id', f'post_{i}')
            post_info['timestamp'] = post.get('data-timestamp', '')
            
            # Classificar tipo de post
            classes = post.get('class', [])
            post_info['viral'] = 'viral' in classes
            post_info['promoted'] = 'promoted' in classes
            
            # Informa√ß√µes do usu√°rio
            user_info = post.find('div', class_='user-info')
            if user_info:
                username_elem = user_info.find('h3', class_='username')
                post_info['username'] = username_elem.get_text().strip() if username_elem else 'N/A'
                
                title_elem = user_info.find('span', class_='user-title')
                post_info['user_title'] = title_elem.get_text().strip() if title_elem else 'N/A'
                
                followers_elem = user_info.find('span', class_='followers')
                if followers_elem:
                    followers_count = followers_elem.get('data-count', '0')
                    post_info['followers'] = self.parse_count(followers_count)
                else:
                    post_info['followers'] = 0
            
            # Conte√∫do do post
            content_div = post.find('div', class_='post-content')
            if content_div:
                text_elem = content_div.find('p', class_='post-text')
                post_info['content'] = text_elem.get_text().strip() if text_elem else ''
                
                # Verificar se tem m√≠dia
                media_elem = content_div.find('div', class_='post-media')
                post_info['has_media'] = media_elem is not None
                
                if media_elem:
                    img = media_elem.find('img')
                    post_info['media_url'] = img.get('src') if img else None
                
                # Links externos
                links_elem = content_div.find('div', class_='post-links')
                if links_elem:
                    external_links = links_elem.find_all('a', class_='external-link')
                    post_info['external_links'] = [link.get('href') for link in external_links]
                else:
                    post_info['external_links'] = []
            
            # M√©tricas de engagement
            interactions = post.find('footer', class_='post-interactions')
            if interactions:
                engagement_stats = interactions.find('div', class_='engagement-stats')
                post_info['engagement'] = self.extrair_engagement(engagement_stats)
                
                # Calcular engagement rate
                post_info['engagement']['engagement_rate'] = self.calcular_engagement_rate(
                    post_info['engagement'], 
                    post_info['followers']
                )
                
                # Hashtags
                hashtags_div = interactions.find('div', class_='hashtags')
                post_info['hashtags'] = self.extrair_hashtags(
                    post_info.get('content', ''), 
                    hashtags_div
                )
                post_info['num_hashtags'] = len(post_info['hashtags'])
            
            # An√°lise do conte√∫do
            content = post_info.get('content', '')
            post_info['content_length'] = len(content)
            post_info['word_count'] = len(content.split())
            post_info['has_emojis'] = bool(re.search(r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF]', content))
            post_info['has_links'] = bool(re.search(r'http[s]?://|www\.', content))
            post_info['has_mentions'] = bool(re.search(r'@\w+', content))
            
            # Data de processamento
            post_info['processed_at'] = datetime.now().isoformat()
            
            posts.append(post_info)
        
        return posts
    
    def extrair_trending_topics(self, html_content: str) -> Dict:
        """
        Extrai t√≥picos em tend√™ncia de dados JSON embutidos.
        
        Args:
            html_content (str): HTML da p√°gina
            
        Returns:
            dict: Dados de trending topics
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Procurar script com dados de trending
        trending_script = soup.find('script', id='trending-topics')
        if trending_script:
            try:
                trending_data = json.loads(trending_script.get_text())
                return trending_data
            except json.JSONDecodeError:
                pass
        
        return {'trending': []}
    
    def extrair_analytics(self, html_content: str) -> Dict:
        """
        Extrai dados de analytics da plataforma.
        
        Args:
            html_content (str): HTML da p√°gina
            
        Returns:
            dict: Dados de analytics
        """
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Procurar script com analytics
        analytics_script = soup.find('script', id='user-analytics')
        if analytics_script:
            try:
                analytics_data = json.loads(analytics_script.get_text())
                return analytics_data
            except json.JSONDecodeError:
                pass
        
        return {'analytics': {}}
    
    def analisar_engagement_patterns(self, posts: List[Dict]) -> Dict:
        """
        Analisa padr√µes de engagement nos posts.
        
        Args:
            posts (list): Lista de posts
            
        Returns:
            dict: An√°lise de padr√µes de engagement
        """
        if not posts:
            return {'erro': 'Nenhum post para analisar'}
        
        df = pd.DataFrame(posts)
        
        # Separar posts virais, promovidos e normais
        posts_virais = [p for p in posts if p.get('viral')]
        posts_promovidos = [p for p in posts if p.get('promoted')]
        posts_normais = [p for p in posts if not p.get('viral') and not p.get('promoted')]
        
        analise = {
            'total_posts': len(posts),
            'posts_virais': len(posts_virais),
            'posts_promovidos': len(posts_promovidos),
            'posts_normais': len(posts_normais),
        }
        
        # An√°lise de engagement
        engagements = [p['engagement']['total_engagement'] for p in posts if 'engagement' in p]
        if engagements:
            analise['engagement_stats'] = {
                'total': sum(engagements),
                'media': sum(engagements) / len(engagements),
                'maximo': max(engagements),
                'minimo': min(engagements)
            }
        
        # An√°lise de hashtags populares
        todas_hashtags = []
        for post in posts:
            todas_hashtags.extend(post.get('hashtags', []))
        
        analise['hashtags_populares'] = dict(Counter(todas_hashtags).most_common(10))
        
        # An√°lise por tipo de conte√∫do
        posts_com_media = len([p for p in posts if p.get('has_media')])
        posts_com_links = len([p for p in posts if p.get('has_links')])
        posts_com_emojis = len([p for p in posts if p.get('has_emojis')])
        
        analise['tipos_conteudo'] = {
            'com_media': posts_com_media,
            'com_links': posts_com_links,
            'com_emojis': posts_com_emojis,
            'percentual_media': (posts_com_media / len(posts)) * 100,
            'percentual_links': (posts_com_links / len(posts)) * 100,
            'percentual_emojis': (posts_com_emojis / len(posts)) * 100
        }
        
        # Usu√°rios mais engajados
        usuarios_engagement = defaultdict(int)
        for post in posts:
            username = post.get('username', 'unknown')
            engagement = post.get('engagement', {}).get('total_engagement', 0)
            usuarios_engagement[username] += engagement
        
        analise['usuarios_top_engagement'] = dict(
            Counter(usuarios_engagement).most_common(5)
        )
        
        # An√°lise temporal (se temos timestamps)
        posts_com_time = [p for p in posts if p.get('timestamp')]
        if posts_com_time:
            analise['posts_por_periodo'] = len(posts_com_time)
        
        # Performance por tipo de post
        if posts_virais:
            viral_eng = [p['engagement']['total_engagement'] for p in posts_virais if 'engagement' in p]
            if viral_eng:
                analise['performance_viral'] = {
                    'engagement_medio': sum(viral_eng) / len(viral_eng),
                    'total_engagement': sum(viral_eng)
                }
        
        if posts_promovidos:
            promo_eng = [p['engagement']['total_engagement'] for p in posts_promovidos if 'engagement' in p]
            if promo_eng:
                analise['performance_promovido'] = {
                    'engagement_medio': sum(promo_eng) / len(promo_eng),
                    'total_engagement': sum(promo_eng)
                }
        
        return analise

def exemplo_uso():
    """Demonstra o uso pr√°tico do SocialMediaScraper."""
    print("üì± === EXEMPLO DE SCRAPING DE REDES SOCIAIS ===")
    print("=" * 58)
    
    # Inicializar scraper com rate limiting
    scraper = SocialMediaScraper(
        requests_per_second=2,
        requests_per_minute=60,
        requests_per_hour=1000
    )
    
    # Simular rede social
    print("1Ô∏è‚É£ Obtendo dados da rede social...")
    html_content = simular_rede_social()
    
    # Extrair posts
    print("2Ô∏è‚É£ Extraindo posts e m√©tricas de engagement...")
    posts = scraper.scrape_posts(html_content)
    
    # Exibir posts encontrados
    print(f"\nüì± === POSTS ENCONTRADOS ({len(posts)}) ===")
    for i, post in enumerate(posts, 1):
        badges = []
        if post.get('viral'):
            badges.append('üî• VIRAL')
        if post.get('promoted'):
            badges.append('üì¢ PROMOVIDO')
        
        status = ' '.join(badges) if badges else ''
        
        print(f"\nüìÑ Post {i}: {post['id']} {status}")
        print(f"   üë§ {post.get('username', 'N/A')} ‚Ä¢ {post.get('user_title', 'N/A')}")
        print(f"   üë• {post.get('followers', 0):,} seguidores")
        
        # Conte√∫do (resumido)
        content = post.get('content', '')[:100] + '...' if len(post.get('content', '')) > 100 else post.get('content', '')
        print(f"   üí¨ {content}")
        
        # Engagement
        eng = post.get('engagement', {})
        print(f"   üìä Engagement: {eng.get('total_engagement', 0):,} total")
        print(f"      ‚ù§Ô∏è  {eng.get('likes', 0):,} curtidas")
        print(f"      üí¨ {eng.get('comments', 0):,} coment√°rios")
        print(f"      üîÑ {eng.get('shares', 0):,} shares")
        print(f"      üîñ {eng.get('saves', 0):,} salvamentos")
        print(f"      üìà {eng.get('engagement_rate', 0):.2f}% engagement rate")
        
        # Hashtags
        hashtags = post.get('hashtags', [])
        if hashtags:
            print(f"   üè∑Ô∏è  {', '.join(hashtags[:5])}")
        
        # M√©tricas adicionais
        print(f"   üìù {post.get('word_count', 0)} palavras")
        
        features = []
        if post.get('has_media'):
            features.append('üì∏ M√≠dia')
        if post.get('has_links'):
            features.append('üîó Links')
        if post.get('has_emojis'):
            features.append('üòä Emojis')
        if post.get('has_mentions'):
            features.append('@ Men√ß√µes')
        
        if features:
            print(f"   ‚ú® {', '.join(features)}")
    
    # Extrair trending topics
    print(f"\nüî• === T√ìPICOS EM TEND√äNCIA ===")
    trending_data = scraper.extrair_trending_topics(html_content)
    
    if trending_data.get('trending'):
        for i, topic in enumerate(trending_data['trending'], 1):
            print(f"{i}. {topic['tag']}")
            print(f"   üìä {topic['posts']} posts ‚Ä¢ {topic['engagement']:,} engagement")
            print(f"   üìà {topic['growth']:+.1f}% crescimento")
    
    # Analytics da plataforma
    print(f"\nüìä === ANALYTICS DA PLATAFORMA ===")
    analytics_data = scraper.extrair_analytics(html_content)
    
    if analytics_data.get('analytics'):
        analytics = analytics_data['analytics']
        print(f"üë• Usu√°rios totais: {analytics.get('total_users', 0):,}")
        print(f"üü¢ Ativos (24h): {analytics.get('active_24h', 0):,}")
        print(f"üìù Posts (24h): {analytics.get('posts_24h', 0):,}")
        print(f"üìä Taxa de engagement: {analytics.get('engagement_rate', 0):.1f}%")
        
        # Tipos de conte√∫do
        content_types = analytics.get('top_content_types', [])
        if content_types:
            print(f"\nüìã Tipos de conte√∫do populares:")
            for content_type in content_types:
                print(f"   ‚Ä¢ {content_type['type'].title()}: {content_type['percentage']}%")
    
    # An√°lise de padr√µes de engagement
    print(f"\nüß† === AN√ÅLISE DE PADR√ïES DE ENGAGEMENT ===")
    analise = scraper.analisar_engagement_patterns(posts)
    
    print(f"üì± Total de posts analisados: {analise['total_posts']}")
    print(f"üî• Posts virais: {analise['posts_virais']}")
    print(f"üì¢ Posts promovidos: {analise['posts_promovidos']}")
    print(f"üìù Posts normais: {analise['posts_normais']}")
    
    # Estat√≠sticas de engagement
    eng_stats = analise.get('engagement_stats', {})
    if eng_stats:
        print(f"\nüìä Engagement total: {eng_stats['total']:,}")
        print(f"üìà Engagement m√©dio: {eng_stats['media']:,.1f}")
        print(f"üöÄ Maior engagement: {eng_stats['maximo']:,}")
        print(f"üìâ Menor engagement: {eng_stats['minimo']:,}")
    
    # Hashtags populares
    hashtags_pop = analise.get('hashtags_populares', {})
    if hashtags_pop:
        print(f"\nüè∑Ô∏è  Top hashtags:")
        for i, (tag, count) in enumerate(list(hashtags_pop.items())[:5], 1):
            print(f"   {i}. {tag}: {count} usos")
    
    # Tipos de conte√∫do
    tipos = analise.get('tipos_conteudo', {})
    if tipos:
        print(f"\nüìã An√°lise de conte√∫do:")
        print(f"   üì∏ Posts com m√≠dia: {tipos['com_media']} ({tipos['percentual_media']:.1f}%)")
        print(f"   üîó Posts com links: {tipos['com_links']} ({tipos['percentual_links']:.1f}%)")
        print(f"   üòä Posts com emojis: {tipos['com_emojis']} ({tipos['percentual_emojis']:.1f}%)")
    
    # Usu√°rios top
    top_users = analise.get('usuarios_top_engagement', {})
    if top_users:
        print(f"\nüëë Top usu√°rios por engagement:")
        for i, (username, engagement) in enumerate(list(top_users.items())[:3], 1):
            print(f"   {i}. {username}: {engagement:,} engagement total")
    
    # Performance por tipo
    if analise.get('performance_viral'):
        viral = analise['performance_viral']
        print(f"\nüî• Performance posts virais:")
        print(f"   üìä Engagement m√©dio: {viral['engagement_medio']:,.1f}")
        print(f"   üöÄ Engagement total: {viral['total_engagement']:,}")
    
    if analise.get('performance_promovido'):
        promo = analise['performance_promovido']
        print(f"\nüì¢ Performance posts promovidos:")
        print(f"   üìä Engagement m√©dio: {promo['engagement_medio']:,.1f}")
        print(f"   üí∞ Engagement total: {promo['total_engagement']:,}")
    
    # Salvar dados
    print(f"\nüíæ === SALVANDO DADOS ===")
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    # CSV dos posts
    df_posts = pd.DataFrame(posts)
    filename_posts = f"social_media_posts_{timestamp}.csv"
    df_posts.to_csv(filename_posts, index=False, encoding='utf-8')
    print(f"‚úÖ Posts salvos em: {filename_posts}")
    
    # JSON da an√°lise completa
    dados_completos = {
        'posts': posts,
        'trending_topics': trending_data,
        'analytics': analytics_data,
        'analise_engagement': analise,
        'metadata': {
            'total_posts': len(posts),
            'scraped_at': datetime.now().isoformat(),
            'rate_limits': {
                'requests_per_second': scraper.rate_limiter.requests_per_second,
                'requests_per_minute': scraper.rate_limiter.requests_per_minute,
                'requests_per_hour': scraper.rate_limiter.requests_per_hour
            }
        }
    }
    
    filename_json = f"social_media_analysis_{timestamp}.json"
    with open(filename_json, 'w', encoding='utf-8') as f:
        json.dump(dados_completos, f, ensure_ascii=False, indent=2, default=str)
    print(f"‚úÖ An√°lise completa salva em: {filename_json}")
    
    # Aplica√ß√µes pr√°ticas
    print(f"\nüí° === APLICA√á√ïES PR√ÅTICAS ===")
    aplicacoes = [
        "üìä Monitoramento de marca e men√ß√µes",
        "üî• Detec√ß√£o de conte√∫do viral",
        "üìà An√°lise de tend√™ncias em tempo real",
        "üéØ Identifica√ß√£o de influenciadores",
        "üí∞ Otimiza√ß√£o de conte√∫do promovido",
        "üì± An√°lise de concorr√™ncia",
        "ü§ñ Sistema de recomenda√ß√µes",
        "‚ö†Ô∏è  Detec√ß√£o de fake news"
    ]
    
    for app in aplicacoes:
        print(f"   {app}")
    
    print(f"\nüîß === DICAS PARA PRODU√á√ÉO ===")
    dicas = [
        "üö¶ Implemente rate limiting rigoroso",
        "‚öñÔ∏è  Respeite termos de uso das APIs",
        "üîê Use autentica√ß√£o OAuth quando dispon√≠vel",
        "üìä Configure monitoramento de quotas",
        "üóÑÔ∏è  Implemente cache inteligente",
        "‚ö° Use processamento ass√≠ncrono",
        "üìß Configure alertas para conte√∫do viral",
        "üõ°Ô∏è  Implemente detec√ß√£o de captcha/bloqueio"
    ]
    
    for dica in dicas:
        print(f"   {dica}")

if __name__ == "__main__":
    exemplo_uso()